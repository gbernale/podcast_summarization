{"podcast_details": {"podcast_title": "NLP Highlights", "episode_title": "141 - Building an open source LM, with Iz Beltagy and Dirk Groeneveld", "episode_image": "https://i1.sndcdn.com/avatars-Rq8FpidJ6YyOFVy8-1exSvw-original.jpg", "episode_transcript": " Hello and welcome to NLP Highlights, a podcast where we discuss recent research in natural language processing. The hosts are members of the Allen NLP team at the Allen Institute for AI. In each episode, we discuss one or more NLP research papers with researchers working in that space. I am Pradeep Dasigi, a research scientist on the Allen NLP team at AI2. I work primarily in natural language processing with the goal of building systems that serve human information needs. My recent work focuses on training robust and data-efficient NLP models that can generalize across domains, tasks and languages. Hi, this is a special episode of NLP Highlights in which instead of discussing a few research papers like we usually do, we will talk about open-sourcing language models. We will start by discussing some of the important decisions one needs to make when building a language model and releasing it. Then we'll also discuss the Open Language Modeling Project or the Allmo project, which is currently an ongoing project at AI2. With me, I have two AI tours. This is Bill Taggi, the research lead of the Allmo project and Dirk Rundl, the engineering lead of the Allmo project. Welcome to the podcast, he's in Dirk. Thanks for having us. Thank you for having us. Yeah, so let's talk about open-sourcing language models. In general, maybe let's start by talking about what it means to open-source a language model. Yeah, so what does it mean? I mean, does it mean releasing the data or the checkpoints or the training logs or something else? Maybe, Is, can you get us started? Yeah, sure. So open-sourcing a language model means you open-source, there are lots of levels, various levels, but completely what we are aiming for in the Allmo project is a completely open-source language model, including the training data and the code that generated the training data and the decisions that went into the design of the training data. And the same for the model, so like the trained model, the code, the weights, the training code, and all the decisions and choices that went into building all of the aspects of the model. We might also add failed runs, checkpoints for failed runs, checkpoints for ablations, that kind of stuff. Cool, yeah. And in general, when you release all these things, all the components that go into training a language model, what kinds of new research questions do you think we can answer? Things that are not possible with closed or proprietary language models? Well, actually, when we started, we looked around to see what we had as starting points. And the thing that's the most useful is if you already have checkpoints for previous runs, you can sort of track your own run along with those previous checkpoints to make sure that you're not lagging significantly behind in performance while you're spending all this money training. I guess that's more of an engineering impact you can have from other people open sourcing their work. And we want to contribute in that vein as well. Great, thanks. Is, do you have anything to add? Yeah, sure. So there are two broad research questions here. How do you build a language model and how you use it in an application or in a download sheet? And both of them have lots of open questions. If we are only able to use language models behind an API that we don't we can only explore one question, which is how to use an existing language language model. And we'll be very limited in the kind of ways and manipulations you can do to adapt the language model for a specific task. So with an open source language model, you can explore so many different ways you can adapt the language model to your task or to your application. And this is a chance for us and for the research community to research the technical details of building these models in the first place. As we're going along with the Olmo project, I find it surprising how many things we have to guess at based on a rumor or based on our own experience, where you would think that it should all be science. It should all be published in a paper somewhere. We should be able to read it and just follow no best practices. But in practice, that's not how it works. And I'm hoping that we can move a little bit further along that route so that the next the next team that does this has to guess a little bit less. Can you give some examples of some of those things? Well, which which training statistics should we track over time? Of course, you track loss. We track grad norm. We someone on our team is interested in tracking the cosine distance between parameter norm and grad norm, because he thinks that that might give us information about whether the model is about to blow up and make thousands of steps into the future. So if we track all these things and we make the statistics public afterwards, maybe someone else can also look at these statistics and find come up with good rules that the next team can follow. Yeah, that's a great segue into the next question I wanted to ask both of you. Some of the decisions that we need to make when we are training the language monitoring scratch. You did talk about specific statistics that we want to track during training. But even before we start training, I'm sure that there are lots of decisions that one needs to make, like what data do you train on? How do you process it? What size of model do you want to train? And how do these decisions affect each other? So, yeah, is can you get us started by talking some of the decisions that you had to make or the team, the team had to make it? And also some of the things that others might have to make? Yeah, you gave a good summary of the high level decisions. You want to balance the amount of training budget you have, the amount of GPU hours you have with the data set size and the model size and with the model size. And also with the available human resources and engineering and social time and people time that you have to build all of these things. So you need to balance all of these things. And within each one of these, there are lots of details like given a we generally know that we are training. We are going to train a decoder only language decoder and also this decoder only language problem. Then there are a huge number of hyper parameters that you need to decide within the design of this model. Do you want to make the model slightly larger and train it on less less or less data or the other way around? Do you want to make the model slightly smaller and change it with more data? How much data you have if you want to make the model smaller and train a little longer? Would you rather have a model be efficient at training time or having or have it be efficient at at inference time with the model? How would you make the model scale to long sequences? And then there are a large number of like little knobs and tweets like this on the data side as well. Maybe Dirk can say more about about those. Sure. The reality is that we can do the big training run only once. So we have to be a little conservative. So our general approach is we we pick something that is fairly safe that we know of work that has maybe been vetted by other teams before. And we place a few strategic bets about things that we could change. So in broad strokes, we're using a palm architecture as published by Google. One strategic bet here is that we're betting on the lion optimizer instead of the atom optimizer that has been de-risked at smaller scale by the mosaic ML team. We're super grateful for that. So we thought we might try it on the data side. The broad strokes are that it's basically a the llama mix of data or the red pajama mix of data with some tweaks such as the Semantic Scholar Corpus that we have great access to since Semantic Scholar is an AI2 project. And the other big deviation is Reddit data. There was no Reddit data explicitly captured in in llama training, but Reddit is a pretty large, fairly high quality source if you filter it right. So we thought we might give that a go. Dirk, you did mention the specific optimizers and other training related norms. Is there anything I think this would be very useful for someone else building a language model as well? Can you elaborate on what kind of a training framework we are using for the Hormone project? Everything is built on PyTorch. We are not using DeepSpeed. We're using only FSDP. We found DeepSpeed a little bit hard to work with, so we thought we'd try this. That has been going pretty well so far. I'm struggling to think what other category of thing you would want to go for. I guess we started with the Mosaic ML code base. They have a really great, fairly minimal example of GPT-2 with various configurations of various sizes. And the key thing there is that it's very hackable. You know, Hugging Face is great. They have a lot of different features in their models and it integrates a lot of kinds of stuff. But those models are very large. We wanted something that we can very quickly put a bunch of tweaks into. And so that's where the Mosaic ML GPT-2 example has really helped us out. Great, thanks. Is one of the things, one of the points that you said that I thought was interesting was how the decisions that we make about training a language model depend on the composition of the team, right? Depending on the size of the team and the number of engineers you have, for example, and the number of researchers you have on the team, the kind of decisions being impacted by those aspects of the team. Can you elaborate on that? Yeah, sure. So the three limitations we have or like constraints that we have are number of two hours that we have for training, our schedule, when we want to deliver or like finish training the model, and the available human resources and engineering resource time. And the three of these constraints, they tell us how much we should invest, the influence of the strategic decisions that Dirk talked about. For example, given the amount of GPU hours that we have and the engineering resources and the human resources that we have, should we spend more time exploring different modeling decisions or exploring different data decisions than doing data adaptations and studying the data set composition? So we decided, given all of these constraints, to focus more on the data side and go with a fairly standard model. Okay, great. Thanks. Right. So the other thing I wanted to talk about related to the modeling decisions is earlier you mentioned that we're following a standard procedure for building language models, or we're building a fairly standard language model. But what does it mean when you say that? What is the standard recipe for building language models? So the standard recipe is you start with pre-changing the model from scratch for a large number of unsupervised tokens, then you continue, you do some alignment where you fine tune it on some instruction data and you continue training on some human feedback. But this is the recipe that seems to be working right now. But there is no, we are broadly following a similar recipe, but there is no reason that this is the optimal recipe. And this is another important reason why the research community should be researching large language models and why the research community should be releasing these language models, because there's no reason this is the only recipe. And there is no reason this is the optimal recipe. It's very possible that it is better to put the instruction data inside as part of the pre-changing data instead of a separate fine tuning phase. It is possible that we don't need the human feedback phase and there are smarter, more clever ways of collecting this data without the laborious human efforts and human efforts to allocate examples. So yes, so in that sense, I will follow what Dirk said. We are mostly following the standard recipe here, but while the high level is standard recipe, while we fine tuning, we're adjusting the knobs in each phase. But we hope that when we make these language models open source, this encourages the research community more to study this recipe and see if there are better ways to do it. And for us, this is the first time we're training at this scale. So we're a little bit conservative with our choices. But we're having thoughts about what to do next time around. And I'd love to take a few more risky bets next time, maybe on the architecture side, maybe on the data side and deviate from the recipe a little bit more and see if we can do a lot better. Right. I can see how these phases in language model training that as you talked about as being separate phases, really, they are really interconnected. Right. And for one example, I keep thinking about is alignment and alignment with human preferences. For example, if you want to ensure that the model does not generate toxic content or misinformation, right, it doesn't maybe doesn't make sense to do it. Think of it as a post pre-training phase where you're trying to align with these differences. Maybe these things need to be baked into the model even from the initial training itself. Right. And I know that there are no good ways or no good answers to questions like these. And it's probably really expensive to train models in many different ways because it usually takes several weeks to months to train these language models. And it takes a lot of computers. Well, yeah, based on what we know so far about how these models are trained, what do you I guess is a question to both is and what are some of the things that you think are worth changing and trying out some interesting deviations from this? You mean beyond what we're trying this time around. So the biggest thing I've been trying to push on is I think we need a large open source mixture of experts model. Almost all of the possibly all of the open source models are dense right now. But there's a lot of buzz around mixture of experts and it should be explored. If it was just up to me and we could do it a second time, that's where I would go. It is pretty clear if you if you start reading on it just a little bit, that you have to guess at a lot more settings if you do this learning rates and optimizers to use and exact architectures and so on. It's a lot more in the air. There's a lot more known about dense models. So this is what makes it more risky. But the potential payoffs are huge. And I will add so pretty few talking about toxic content specifically and making the model not generate toxic content. So this is the question that touches every aspect of the training of the model from the data all the way to instruction, tuning and alignment and stuff. And we know that people have managed to train models that would be large that would drop largely avoid seeing something toxic or offensive. But the research, the energy research community doesn't know the details of how to actually do this. So the approach we are taking right now is on the pre training data side, we are filtering out a significant percentage of the toxic content. You don't want to filter out everything. You still want to keep keep something so that the model knows about these things. But you still filter out a significant percentage of it. And this is something that we are ablating on the data side. And when we are figuring out the right filtering method and the best data set composition, then there are two more steps you can do later on. One of them on the alignment side, where you train it on examples that tells the model don't answer this question if the question is toxic. And there's an easier method that you can do, which is post processing, which is a post processing thing. You have a small classifier that checks the output. If the output is toxic, you opt out. The model says I don't know or you don't generate this out. You don't serve this output to the user. But the technical details of how to do the alignment, what is the best data set to use to train the post hoc classifier. All of these things are still open. One of the specific ways you can do alignment that takes into account toxicity is control tokens. You have examples that is the model. You have examples that the model which content is offensive and which content is toxic, which content is not toxic. And then you train the model with some control token, then at training time, then at inference time, you change the token. And that will get the model to generate, to mostly generate the non-toxic content. And there are so many ways to do this. The control token is one method that's a simplification of reinforcement learning. But there are even simpler methods that keep showing up. This is another reason that open source language models should be an important thing because this is where people can start executing simpler methods that would do the same job. Great. Thanks a lot for that overview. Right. So let's talk particularly about the goals of the Allmo project. We did talk about the goals briefly a couple of times already, but maybe let's try to contrast what we are doing at AI2 with the Allmo project, with other similar projects at other organizations. There are already several closed, appropriated language models and there are also several open source language models as well. And I'm sure many people are already working on more projects as we speak. So can you try and talk about how the Allmo project is different from some of those projects? Yeah. So the stated goal of the Allmo project is to keep academia and open source developers in the game. We see a lot of formerly public research disappearing behind closed doors and we're worried about it. Open AI is publishing less and less. Google is keeping things under wraps and we're worried that the open community will lose access to state of the art models and artifacts become irrelevant. A similar thing happened to research and information retrieval where most of the work now happens inside of Google and never gets published at all. So we're going to open up the entire process of building the Allmo model, starting with the code and the weights, of course, but intermediate checkpoints, models that were the result of ablations, logs of which decisions were made and why and so on. Maybe this is a good time to give a shout out to the elite AI who have been following this approach for a while. We basically looked at that and said, that's great. Let's do more of that. So a few more things that make Allmo unique. One of them is the hardware we use for training. So we are training on AMD GPUs while almost all existing language models were trained on Nvidia GPUs or on TPUs. So we have carefully benchmarked the hardware, making sure it supports things like BF16, which is important for training stability and flash attention, which is important for training or longer sequences. And we recently started training 7P models and we are optimistic that the hardware will continue to scale to the 7PB scale. Another angle is the pre-training data set design. Given all the text on the web, how do we build the pre-training corpus that gives us the best resulting model? This is a research question that is significantly under-exported in the literature. It is difficult to study because curating and processing large data sets is a difficult engineering problem. And once you have this data curated, it is difficult and expensive to run many, many ablations and many, many experiments to ablate different data design decisions. So this is a problem we are focusing on. We want to find the best setup and the best recipe in terms of filtering the pre-training data, deduplicating the pre-training data and finding the right mix of the different sources that we can include in the pre-training data set. Another focus for OLMO is scientific documents. While we aim for OLMO to be a general purpose model that works for all kinds of applications, we also want it to be particularly good for processing and understanding scientific documents. So some portion of the pre-training data is going to be from scientific documents. And this is also something that we will consider at instruction tuning and make sure that some of the instruction tuning data is from the scientific domain. The OLMO project doesn't have one central research question. It ties together several internal efforts that we already have that we're trying to answer separate, more detailed questions. There are some questions about architecture choices that might work like the Lion Optimizer. There's been, even before the OLMO project, a lot of interest at AI2 about the importance of data, how to filter, how to deduplicate, how much code to use. In some sense, each one of these things could be a separate paper. They might not end up being separate papers each, but we don't quite know yet how we're going to distribute the research questions across the ablations that we can run. Oh, I guess one other thing I should mention is energy usage. There's these two people at AI2 interested in measuring the energy usage of large language model training. They probably have their own set of research questions about that. Is Juhi having anything to add? So I like to think of OLMO as enabling other research projects that would have been difficult otherwise. I will give you two examples. The first is we hope to empower the research on how to close the gap between open models and other state of the art closed models. And we have recent results that show that this gap cannot be closed purely by instruction training on top of models like Llama, for example. So we need more capable base language models than what is currently available. And we hope for OLMO to play a role in enabling this research. Another example is less on the technical side and more on the legal and ethical side. So we want to provide an example and maybe a blueprint that other researchers can follow on how to navigate the difficult legal and ethical issues around licensing, releasing models, releasing pre-training data and also releasing human feedback data. These are difficult questions, and I don't think we will find the perfect answer for all of them. But we can make we can try to make progress here and hopefully make it easier for the community to navigate these issues. Great, thanks. A couple of times in this conversation so far, I guess both of you mentioned how we started out with projects that are research questions that we were trying to answer at AI2 already and use those research efforts to contribute to the OLMO project. I think that's that's a really cool thing about this project. And that's one of the things that I'm most excited about as to how we've organized the OLMO projects internally at AI2. We have people from various teams who've decided mostly bottom up to work together towards building the OLMO project. And I mean, since you've been involved in the project since the beginning, can you give us an overview of how this happened? AI2 has a large number of talents in the research side and also in the engineering side. Everybody was exploring different aspects of NLP and trying to advance the state of the art in NLP research and engineering. Some of these efforts were about how to build the language model, how to study the data, how to evaluate, how to use the language model in some downshame use case. And everybody each one was trying to trying to write a research paper about all of these aspects. And this project is a good way and is a good way to align these efforts, make them more impactful and bridge the bridge, a large number of existing efforts inside the AI2 to make them more more toward a single big goal. Great. Thanks. Yes. I as I said earlier, I think this is it's really cool. We have the project essentially started bottom up and we realized that there were people who are already working on answering some of these research questions that are relevant to building a large language model. So, yeah, I think I think it's really exciting. Let's also talk about the external collaborators involved in this project. You already mentioned AMD. Dirk, can you give us give us an overview of who else is involved in this project? So the big ones are, of course, AMD and and CSC who made the CSC has made the Lumi cluster available to us for this project, without which we we couldn't be thinking about the scale that we're training at right now. There are a lot a lot of others. I've mentioned Mosaic ML a couple of times. They have shared a lot of data with us and we started with their code base. The open source community is is absolutely huge in this. If I try to name all the projects, I'll forget one. So I will I will not try. But I guess Elu, there is, of course, the biggest one of them. So they have like with the with the Pithia project that has made a big impact on us. Also, the Bloom project, which is not not in use, but the Bloom project was a big influence for us. And then there are there are a number of other companies. Surge is one of them for getting for getting instruction tuning data. I'm actually not to include into that side of things, maybe is knows more about those vendors, the vendors for data. I mean, yes, search is the primary vendor that we are working with to get instruction data. We explored a few others, but search is the most viable one for us right now. And I will add to this that this is this is a large project that we cannot build on our. I will add to this that we are open to more collaborations. And this is a project that we want to make it available for the open research community. So we will come more contributions and more collaborations with people. Like it would be great if more of the open source efforts to build these language models are more coordinated. We explore different research questions, not trying to do the same thing and pool resources together. Maybe one of us started in the model and then another one continue, but continue to the model a lot a lot longer, which is going to make it to to end up with a better, a better single checkpoint. So more more of these collaborations will be will be great for us and for the social. I think that's actually a very important point is because by its nature, the open source community isn't that unified. It will often happen that different teams are exploring the same questions at the same time. And I think as a community, we can do a lot better if we if we avoid that as much as possible. I know it's not always possible because people have compute allocations and they need to produce results on a certain timeline. And sometimes you've got to train with what you have. But we should at least try to get together and explore different parts of the of the third space. We've tried that with a number of different efforts, but I know there's more out there. We could we can always be doing a better job coordinate. OK, so the people listening to this podcast, either individuals or organizations, if they're interested in collaborating and helping with this project, how would you recommend that we show to us? Most formal way to reach out to us is by filling in a form we have set up for this purpose. There is a link that we can hopefully put at the bottom of the podcast. This is a great way for either companies or other open source efforts to get in touch. The form might be a little bit formal, but we'll route it to the right people. But also just reach out to us on Twitter. I think we're both fairly active there. If you don't want everyone to know, you know, send us a DM. Great. Thanks. OK, I'll make sure to include a link to the form in the description of the podcast of this episode. Right. Thanks a lot for thanks a lot to both of you for giving us an overview of the Allmo project and also talking about open sourcing language models in general. Is there anything that you wanted to talk about that I didn't ask you? No, this this was great. Yeah, thank you for the opportunity. And I was fun sharing with you about this topic. All right. Thanks a lot."}, "podcast_summary": "In this podcast episode, the hosts discuss the topic of open-sourcing language models. They are joined by Bill Taggi, the research lead, and Dirk Rundl, the engineering lead of the Allmo project at AI2. They start by discussing what it means to open-source a language model, including releasing the data, code, and design decisions involved in building the model. They highlight that open-sourcing language models enables researchers to explore different ways to adapt the model for specific tasks and applications, as well as study the technical details of building these models. \n\nThe hosts and guests talk about the decisions involved in training a language model, such as what data to use, how to process it, and what size of model to train. They mention that the team aims to balance factors like training budget, available resources, and the need for generalization across domains, tasks, and languages. They also discuss the importance of tracking training statistics and the potential for open-sourced models to help other teams by providing insights and best practices.\n\nThe conversation touches on various research questions related to language model training, including the need for better recipes and optimizations, the challenge of preventing the generation of toxic content, and the potential for exploring alternative approaches like mixture of experts models. The guests highlight that the OLMO project at AI2 aims to empower other research projects, contribute to closing the gap between open models and closed models, and provide a blueprint for navigating legal and ethical considerations in open-sourcing language models.\n\nThey also mention collaborations with companies like AMD and CSC, as well as the importance of coordinated efforts within the open-source community. The guests mention that they are open to more collaborations and encourage interested individuals or organizations to reach out to them through a form or on Twitter.\n\nOverall, the episode provides insights into the Allmo project at AI2 and the broader topic of open-sourcing language models, highlighting the potential for research and innovation in this area.", "podcast_guest": {"name": "Bill Taggi", "summary": null}, "podcast_highlights": "Here are the most relevant answers to the important questions discussed in the podcast:\n\n1. What does it mean to open-source a language model?\n- Open-sourcing a language model means releasing not only the data, but also the code, training logs, checkpoints, and the decisions that went into building the model.\n\n2. What new research questions can be answered with open-source language models?\n- Open-source language models allow researchers to explore different ways to adapt the model to specific tasks or applications. It also enables further research into the technical details of building these models.\n\n3. What are some of the decisions made when building and training a language model?\n- Decisions include choosing the training data, data processing methods, model size, and balancing training budget and resources. Other decisions involve choosing hyperparameters, model efficiency, and scalability to long sequences.\n\n4. How are the decisions and choices made during training affected by the team's composition?\n- The decisions and choices depend on the resources, such as the number of GPU hours, engineering resources, and human resources available. The team's composition influences how these resources are prioritized and allocated.\n\n5. How is the Allmo project different from other similar projects?\n- The Allmo project aims to keep academia and open-source developers in the game by open-sourcing the entire process of building a language model. It utilizes AMD hardware, focuses on scientific documents, and collaborates with various organizations to address research questions and navigate legal and ethical issues.\n\n6. How can external collaborators get involved in the Allmo project?\n- External collaborators can fill out a form or reach out on Twitter to express their interest in collaborating with the Allmo project. Collaboration can include sharing research, pooling resources, and exploring different aspects of language model development.\n\nOverall, the Allmo project seeks to advance the state of language models, encourage open research, and foster collaboration within the NLP community."}